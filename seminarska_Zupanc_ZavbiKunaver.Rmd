---
title: "Primerjava ploščin pod ROC krivuljo"
author: "Vesna Zupanc in Anja Žavbi Kunaver"
date: "3 3 2020"
output:
  html_document:
    toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
# library(MASS)
library(knitr)
library(mvtnorm)
library(ROCR)
```

# Uvod

V seminarski nalogi želimo prikazali uporabo ROC krivulj in kako nam pomagajo pri odločanju med dvema klasifikatorjema. ...

# Teoretične osnove

## ROC krivulje in AUC

Za začetek si poglejmo, kaj so to ROC krivulje in kaj je mera AUC. ROC krivulje (ang.ROC curve - receiver operating characteristic curve) je grafični prikaz, ki prikazuje uspešnost klasifikacijskega modela pri vseh pragovih klasifikacije. Prikazuje dva parametra:

* Stopnja resnično poztivnih (TPR - True positive rate)
* Stopnja lažno pozitivnih (FPR - False positive rate)

Definirajmo še kratice:

* TP (true positive): št. resnično pozitivnih primerov
* TN (true negative): št. resnično negativnih primerov
* FP (false positive): št. lažno pozitivnih primerov
* FN (false negative): št. lažno negativnih primerov

Stopnja resnično pozitivnih (TPR) je tako definirana kot:

$$TPR = \frac{TP}{TP+FN}$$
Stopnja lažno pozitivnih (FPR) pa kot:

$$FPR = \frac{FP}{FP+TN}$$
ROC krivulja nariše TPR v primerjavi z FPR, pri različnih pragovih klasifikacije. Z znižanjem praga za razvrstitev je več postavk opredeljenih kot pozitivnih, kar povečuje tako napačne kot resnične pozitivne. 

Neka slika ROC? 

AUC (Area Under the ROC Curve) pa predstavlja ploščino pod ROC krivuljo in s tem predstavlja skupno merilo uspešnosti za vse možne pragove klasifikacije. Torej, ROC predstavlja verjetnostno krivuljo, AUC pa predstavlja stopnjo ali merilo ločljivosti. Pove nam, koliko model razlikuje med posameznimi razredi. Višji kot je AUC, boljši je model pri napovedovanju oziroma določanju razredov. 

Primer takšnega klasifikacijskega problema je naprimer določanje bolnih in zdravih oseb na podlagi nekega markerja. V tem primeru visok AUC pomeni boljše razlikovanje med bolnimi in zdravimi, kar je običajno tudi naš cilj. 

Kot smo omenili že v uvodu, pa se bomo V sklopu naloge odločali med dvema različnima markerjema. Tudi v tem primeru, si želimo marker, ki ima višjo vrednost AUC. Na primer, da želimo da podlagi krvne preiskave določiti, ali mora neka oseba na nadaljne preiskave ali ne. Lahko bi namesto AUC za merilo kakovosti markerja vzeli samo stopnjo resnično pozitivnih primerov in jo maksimizirali. S pomočjo takega kriterija, bi najverjetneje zajeli večji delež bolnih, vendar pa se nam v tem primeru lahko zgodi, da bo na dodatnih presikavah tudi veliko zdravih ljudi. Tako je najboljša mera v takem primeru AUC, saj s tem preverjamo kako dobro nek marker loči med bolnimi in zdravimi. 

## Permutacijski test

Za testiranje hipotez bomo uporabljali permutacijski test. Permutacijski test je zelo splošen pristop za testiranje statističnih hipotez, saj nima predpostavk o porazdelitvah in je zato tudi zelo primeren, kadar podatki niso skladni s predpostavko o njihovi porazdelitvi. 

Porazdelitev testne statistike je generirana iz podatkov samih ob ničelni hipotezi, ki predpostavlja, da so vsi možni pari dveh spremenljivk enako verjetni. To dosežemo tako, da podatke ene spremenljivke naključno porazdelimo, drugo spremenljivko pa fiksiramo. Na koncu pa primerjamo dobljeno vrednost testne statistike in iz generirane porazdelitve odčitamo p-vrednost.

Kaj več tukaj? Kaj se zgodi, če sta markerja odvisna, ali je to treba kaj upoštevati


# Ničelna domneva

Najina ničelna domneva je, da sta markerja enakovredna, oziroma, da sta njuni vrednosti AUC enaki.
Pri permutacijskih testih, kjer imava za testno statistiko razliko AUC obeh markerjev je 
$H_0:$ razlika je enaka 0.
Pri permutacijskih testih, kjer imava za testno statistiko razmerje obeh AUC obeh markerjev je
$H_0:$ razmerje je enako 1.

# Simulacije podatkov

Poskusili sva z različnimi simulacijami podatkov. Če sva vzeli zelo velik vzorec, so p-vrednosti pri vseh štirih testih prišle enake 0, torej sva vedno zavrnili ničelno domnevo. Rezultati so pričakovani, saj sva podatke simulirali tako, da imata markerja različne AUC vrednosti in pri večjem vzorcu ničelno domnevo lažje zavrnemo. Na podlagi te ugotovitve sva se odločili za simulacije manjših vzorcev. Pri vsakem primeru natančno opiševa postopek generiranja podatkov.

# Permutacijski testi

Najprej narediva permutacijski test, kjer permutirava markerja in gledava razliko. Označiva ga kot test1.

```{r}
test1 <- function(x,y){
  razlika = c()
  for (k in 1:1000){
    # Korak 1:
    xp1<-x[sample(1:n),1] #permutacija x-a
    xp2<-x[sample(1:n),2]
    
    # Korak 2:
    #AUC = ploščina pod ROC krivuljo
    df <- data.frame(xp1,y)
    colnames(df) = c("predictions","labels")
    pred <- prediction(df$predictions, df$labels)
    auc_ROCR1 <- performance(pred, measure = "auc")
    auc_ROCR1 <- auc_ROCR1@y.values[[1]]
    
    df <- data.frame(xp2,y)
    colnames(df) = c("predictions","labels")
    pred <- prediction(df$predictions, df$labels)
    auc_ROCR2 <- performance(pred, measure = "auc")
    auc_ROCR2 <- auc_ROCR2@y.values[[1]]
    
    razlika[k] = auc_ROCR1 - auc_ROCR2
  }
  hist(razlika, main="")
  p.vrednost <<- sum(razlika>originalna_razlika)/1000
}
```

Za drugi permutacijski test (test2) permutirava izid in gledava razliko.

```{r}
test2 <- function(x,y){
  razlika = c()
  for (k in 1:1000){
    yp<-y[sample(1:n)] #permutacija y-a
    
    df <- data.frame(x[,1],yp)
    colnames(df) = c("predictions","labels")
    pred <- prediction(df$predictions, df$labels)
    auc_ROCR1 <- performance(pred, measure = "auc")
    auc_ROCR1 <- auc_ROCR1@y.values[[1]]
    
    df <- data.frame(x[,2],yp)
    colnames(df) = c("predictions","labels")
    pred <- prediction(df$predictions, df$labels)
    auc_ROCR2 <- performance(pred, measure = "auc")
    auc_ROCR2 <- auc_ROCR2@y.values[[1]]
    
    razlika[k] = auc_ROCR1 - auc_ROCR2
  }
  hist(razlika, main="")
  p.vrednost <<- sum(razlika>originalna_razlika)/1000
}
```

Pri tretjem permutacijskem testu (test3) permutirava markerja in gledava razmerje.

```{r}
test3 <- function(x,y){
  razmerje = c()
  for (k in 1:1000){
    xp1<-x[sample(1:n),1] #permutacija x-a
    xp2<-x[sample(1:n),2]
    
    df <- data.frame(xp1,y)
    colnames(df) = c("predictions","labels")
    pred <- prediction(df$predictions, df$labels)
    auc_ROCR1 <- performance(pred, measure = "auc")
    auc_ROCR1 <- auc_ROCR1@y.values[[1]]
    
    df <- data.frame(xp2,y)
    colnames(df) = c("predictions","labels")
    pred <- prediction(df$predictions, df$labels)
    auc_ROCR2 <- performance(pred, measure = "auc")
    auc_ROCR2 <- auc_ROCR2@y.values[[1]]
    
    razmerje[k] = auc_ROCR1/auc_ROCR2
  }
  hist(razmerje, main="")
  p.vrednost <<- sum(razmerje>originalno_razmerje)/1000
}
```

Za zadnji permutacijski test (test4) permutirava izid in gledava razmerje.

```{r}
test4 <- function(x,y){
  razmerje = c()
  for (k in 1:1000){
    yp<-y[sample(1:n)] #permutacija y-a
    
    df <- data.frame(x[,1],yp)
    colnames(df) = c("predictions","labels")
    pred <- prediction(df$predictions, df$labels)
    auc_ROCR1 <- performance(pred, measure = "auc")
    auc_ROCR1 <- auc_ROCR1@y.values[[1]]
    
    df <- data.frame(x[,2],yp)
    colnames(df) = c("predictions","labels")
    pred <- prediction(df$predictions, df$labels)
    auc_ROCR2 <- performance(pred, measure = "auc")
    auc_ROCR2 <- auc_ROCR2@y.values[[1]]
    
    razmerje[k] = auc_ROCR1/auc_ROCR2
  }
  hist(razmerje, main="")
  p.vrednost <<- sum(razmerje>originalno_razmerje)/1000
}
```

# Primer 1

## Simulacija podatkov

Najprej sva se odločili za simulacijo vzorca velikosti 100. Markerja sva generirali iz normalne porazdelitve in sicer prvega iz $N(0,1)$ in drugega iz $N(2,1)$. Kovarianco med njima sva nastavili na 0.4. Spremenljivka $Y$ je pokazatelj, ali ima posameznik bolezen ali ne, torej je porazdeljena Bernoullijevo. Generirali sva jo kot linearno kombinacijo markerjev in sicer $Y = 6*X_1+2*X_2 + \epsilon$, kjer je $\epsilon$ napaka, ki je standardno normalno porazdeljena. Vrednosti sva pretvorili v 0 in 1 tako, da je polovica vrednosti 1 (tiste z večjo vrednostjo od mediane) in polovica 0 (tiste z manjšo vrednostjo).

```{r fig.cap="ROC krivulji obeh markerjev"}
n=100 #najprej vzemi velik n, nato lahko manjše vzorce (najprej sva probali z 10000)
korelacije = matrix(0.4, nrow=2, ncol=2)
diag(korelacije) = 1
x <- rmvnorm(n=n, mean=c(0,2), sigma=korelacije)
y = 6*x[,1]+2*x[,2] + rnorm(n,0,1)
#median(y) #meja, od kje naprej so bolni, da jih je približno polovica
meja=4
y[y<meja] <- 0
y[y>=meja] <- 1

df <- data.frame(x[,1],y)
colnames(df) = c("predictions","labels")
pred <- prediction(df$predictions, df$labels)
perf <- performance(pred,"tpr","fpr")
plot(perf,col="orange")

auc_ROCR1 <- performance(pred, measure = "auc")
auc_ROCR1 <- auc_ROCR1@y.values[[1]] #želimo čim večjo vrednost

df <- data.frame(x[,2],y)
colnames(df) = c("predictions","labels")
pred <- prediction(df$predictions, df$labels)
perf <- performance(pred,"tpr","fpr")
plot(perf,col="blue", add=TRUE)

auc_ROCR2 <- performance(pred, measure = "auc")
auc_ROCR2 <- auc_ROCR2@y.values[[1]]

#shraniva za permutacijske teste
originalna_razlika = auc_ROCR1 - auc_ROCR2
originalno_razmerje = auc_ROCR1/auc_ROCR2
```

```{r}
podatki <- cbind(x,y)
colnames(podatki) = cbind("x1","x2","y")
tabela1 <- head(podatki)
kable(tabela1, caption="Izsek iz tabele podatkov")
```

## Preverjanje testne statistike pod ničelno domnevo

Najprej preveriva porazdelitev testne statistike pod ničelno domnevo.

```{r results=FALSE}
y.test = 2*x[,1]+2*x[,2] + rnorm(n,0,1)
#median(y.test) #meja, od kje naprej so bolni, da jih je približno polovica
meja=4
y.test[y.test<meja] <- 0
y.test[y.test>=meja] <- 1
```

```{r fig.cap="Histogram vrednosti testne statistike pod H0 za test1"}
test1(x,y.test)
```

```{r fig.cap="Histrogram vrednosti testne statistike pod H0 za test2"}
test2(x,y.test)
```

```{r fig.cap="Histrogram vrednosti testne statistike pod H0 za test3"}
test3(x,y.test)
```

```{r fig.cap="Histrogram vrednosti testne statistike pod H0 za test4"}
test4(x,y.test)
```

Vidimo, da je porazdelitev testne statistike pri vseh štirih testih podobna normalni.??

## Rezultati testov

```{r fig.cap="Porazdelitev testih statistik za simulacije test1"}
test1(x=x,y=y)
abline(v=originalna_razlika, col="red", add=TRUE)
```

Dobljena p-vrednost za test1 je `r round(p.vrednost,3)`.

```{r fig.cap="Porazdelitev testih statistik za simulacije test2"}
test2(x=x,y=y)
abline(v=originalna_razlika, col="red", add=TRUE)
```

Dobljena p-vrednost za test2 je `r round(p.vrednost,3)`.

```{r fig.cap="Porazdelitev testih statistik za simulacije test3"}
test3(x=x,y=y)
abline(v=originalno_razmerje, col="red", add=TRUE)
```

Dobljena p-vrednost za test3 je `r round(p.vrednost,3)`.

```{r fig.cap="Porazdelitev testih statistik za simulacije test4"}
test4(x=x,y=y)
abline(v=originalno_razmerje, col="red", add=TRUE)
```

Dobljena p-vrednost za test4 je `r round(p.vrednost,3)`.


# Lastnosti testov

Preverit je potrebno lastnosti vseh štirih permutacijskih testov.

Kateri test bi bil najustreznejši?


------------------------------------------------------------------------------
# Zapiski

## Osnovna ideja ROC krivulje

Karakteristike delovanja sprejemnika (Receiver Operating Characteristics - ROC) so grafične metode, ki se ukvarjajo s strojnim učenjem.
Graf ROC je dvodimenzionalen graf, ki prikazuje razmerje med deležem resničnih pozitivnih primerov (TPR), ki jih odkrijemo in deležem lažnih pozitivnih primerov (FPR). Na osi *x* prikazujemo delež lažnih pozitivnih primerov, na osi *y* pa delež resničnih pozitivnih primerov (Biček, 2009).


## Nametane informacije

Narišemo lahko več ROC krivulj glede na prage (za vsak prag svojo).

Točka $(0,0)$ je značilna za vsak ROC graf.
Točk ne smemo obravnavati posamično, ker bi drugače bila oblika grafa odvisna od tega, katero točko prvo izberemo za obravnavo.

Na strani 13 v (Biček, 2009) je primer algoritma za ROC (psevdokoda).

Uporabni primeri v tej diplomi.

# Viri

* Biček, M. (2009). *Grafični gradnik za merjenje kvalitete klasifikatorja s pomočjo krivulj* (Diplomsko delo). Univerza v Ljubljani, Fakulteta za računalništvo in informatiko, Ljubljana.

